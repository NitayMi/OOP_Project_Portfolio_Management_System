from abc import ABC, abstractmethod
import ollama
from rag_engine import query
from rag_loader import get_collection  # ×˜×¢×™× ×ª ×”×§×•×œ×§×©×Ÿ ×ª×ª×‘×¦×¢ ×¨×§ ×›×©×¦×¨×™×š

# # ==== ×××©×§ ×›×œ×œ×™ ×œ×›×œ AI Advisor (×—×•×‘×”) ====
# class IAIAdvisor(ABC):
#     @abstractmethod
#     def get_advice(self, question: str, portfolio_data=None) -> str:
#         """
#         ××ª×•×“×” ×œ×§×‘×œ×ª ×™×™×¢×•×¥ AI. ×—×•×‘×” ×œ×××© ×‘×›×œ ××—×œ×§×” ×©××™×™×©××ª ××ª ×”×××©×§.
#         """
#         pass

# # ==== ××—×œ×§×” ×©××™×™×©××ª RAG AI ×¢× ×©××™×œ×ª×•×ª ×•× ×™×ª×•×— ×ª×™×§ ×”×©×§×¢×•×ª ====
# class AIAdvisorRAG(IAIAdvisor):
#     def __init__(self, model='deepseek-r1:7b', collection=None):
#         """
#         :param model: ×©× ×”××•×“×œ ×œ×©×™××•×© ×‘-ollama.
#         :param collection: ×—×™×‘×•×¨ ×œ-ChromaDB (××•×–×¨×§ ×-main).
#         """
#         self.model = model
#         self.collection = collection  # ×¢×•×‘×¨ ××‘×—×•×¥, ×œ× × ×•×¦×¨ ×¤× ×™××™!

#     def get_advice(self, question: str, portfolio_data=None) -> str:
#         """
#         ××—×–×™×¨ ×™×™×¢×•×¥ ××‘×•×¡×¡ AI ×‘×”×ª×‘×¡×¡ ×¢×œ ×©××œ×” ×•×ª×™×§ ×”×”×©×§×¢×•×ª.
#         :param question: ×©××œ×ª ×”××©×ª××©.
#         :param portfolio_data: ×¤×¨×˜×™ ×”×ª×™×§ ×©×œ ×”××©×ª××©.
#         :return: ××—×¨×•×–×ª ×ª×©×•×‘×”.
#         """
#         print("ğŸ” Getting AI advice with RAG and personalized portfolio context...")

#         # ×‘× ×™×™×ª ×§×•× ×˜×§×¡×˜ ×©×œ ×”×ª×™×§
#         portfolio_context = ""
#         if portfolio_data:
#             portfolio_context = "\n".join([
#                 f"- {item.name}, {item.security_type}, Sector: {item.sector}, "
#                 f"Risk: {item.variance}, Amount: {item.ammont}"
#                 for item in portfolio_data
#             ])

#         # ×©×œ×™×¤×ª ××™×“×¢ ×ª×•××š ××”-RAG
#         if self.collection is None:
#             raise ValueError("Collection must be provided!")
#         rag_context = query(question=question, collection=self.collection, top_k=3)


#         # ×‘× ×™×™×ª ×”×©××œ×” ×”××œ××” ×¢× ×”×§×©×¨
#         full_question = f"""
# You are a professional investment advisor AI.

# User's Risk Profile and Portfolio:
# {portfolio_context}

# Relevant Background Knowledge:
# {rag_context}

# Question:
# {question}

# Provide a professional and personalized investment recommendation.
# """

#         # ×©×œ×™×—×ª ×”×©××œ×” ×œ××•×“×œ
#         response = ollama.generate(
#             model=self.model,
#             prompt=full_question
#         )
#         return response.get('response', 'âŒ No valid response')









class IAIAdvisor(ABC):
    @abstractmethod
    def get_advice(self, question: str, portfolio_data=None) -> str:
        pass

class AIAdvisorRAG(IAIAdvisor):
    def __init__(self, model='deepseek-r1:7b'):
        """
        :param model: ×©× ×”××•×“×œ ×œ×©×™××•×© ×‘-ollama.
        """
        self.model = model
        self.collection = None  # ×”×§×•×œ×§×©×Ÿ ×œ× × ×˜×¢×Ÿ ×¢×“×™×™×Ÿ!

    def ensure_collection_loaded(self):
        """ ×˜×•×¢×Ÿ ××ª ChromaDB ×¨×§ ×× ×¢×“×™×™×Ÿ ×œ× × ×˜×¢×Ÿ """
        if not hasattr(self, "collection_loaded") or not self.collection_loaded:
            print("â³ Loading AI Collection...")
            self.collection = get_collection()
            self.collection_loaded = True  # ××‘×˜×™×— ×˜×¢×™× ×” ×¤×¢× ××—×ª ×‘×œ×‘×“
            print("âœ… AI Collection Loaded!")


    def get_advice(self, question: str, portfolio_data=None) -> str:
        """ ××—×–×™×¨ ×™×™×¢×•×¥ ××‘×•×¡×¡ AI ×‘×”×ª×‘×¡×¡ ×¢×œ ×©××œ×” ×•×ª×™×§ ×”×”×©×§×¢×•×ª """
        if not hasattr(self, "collection_loaded") or not self.collection_loaded:
            self.ensure_collection_loaded()
            self.collection_loaded = True  # ××¡××Ÿ ×©×”×§×•×œ×§×©×Ÿ ×›×‘×¨ × ×˜×¢×Ÿ


        print("ğŸ” Getting AI advice with RAG and personalized portfolio context...")
        
        # ×™×¦×™×¨×ª ×§×•× ×˜×§×¡×˜ ×ª×™×§ ×”×©×§×¢×•×ª
        portfolio_context = ""
        if portfolio_data:
            portfolio_context = "\n".join([
                f"- {item.name}, {item.security_type}, Sector: {item.sector}, "
                f"Risk: {item.variance}, Amount: {item.ammont}"
                for item in portfolio_data
            ])

        # ×©×œ×™×¤×ª ××™×“×¢ ×ª×•××š ××”-RAG
        rag_context = query(question=question, collection=self.collection, top_k=3)

        # ×‘× ×™×™×ª ×”×©××œ×” ×”××œ××” ×¢× ×”×”×§×©×¨
        full_question = f"""
You are a professional investment advisor AI. 
Provide a short and actionable investment recommendation in **2-3 sentences** only. Avoid long explanations.

User's Risk Profile and Portfolio:
{portfolio_context}

Relevant Background Knowledge:
{rag_context}

Question:
{question}

Provide a professional and personalized investment recommendation.
"""

        response = ollama.generate(
            model=self.model,
            prompt=full_question
        )

        # ×‘×“×™×§×” ×”×× ×”×ª×©×•×‘×” × ×—×ª×›×ª
        full_response = response.get('response', '')
        if not full_response:
            return "âŒ No valid response"

        print(f"ğŸ” Full AI Response: {full_response}")  # Debugging print
        return full_response


        # # ×©×œ×™×—×ª ×”×©××œ×” ×œ××•×“×œ
        # response = ollama.generate(
        #     model=self.model,
        #     prompt=full_question
        # )
        # return response.get('response', 'âŒ No valid response')
