import pytest
import sys
import os
from unittest.mock import patch, MagicMock

# 住驻转 转 驻专拽   砖 爪
sys.path.insert(0, os.path.abspath(os.path.dirname(__file__)))

from ollamamodel import AIAdvisorRAG, get_collection
import rag_loader


def test_no_duplicate_advice_prints():
    """ 拽  砖 驻住转 驻转 砖 拽专 -AI """
    ai_advisor = AIAdvisorRAG()
    question = "What is 1+1?"
    
    with patch("builtins.print") as mock_print:
        ai_advisor.get_advice(question)
        
        #  砖注转 "Getting AI advice..." 驻注 专拽 驻注 转
        messages = [call[0][0] for call in mock_print.call_args_list]
        assert messages.count(" Getting AI advice with RAG and personalized portfolio context...") == 1


def test_chromadb_loads_only_once():
    """ 拽  砖-ChromaDB 注 专拽 驻注 转 """
    ai_advisor = AIAdvisorRAG()
    
    with patch("ollamamodel.get_collection", wraps=rag_loader.get_collection) as mock_get_collection:
        ai_advisor.ensure_collection_loaded()
        ai_advisor.ensure_collection_loaded()
        
        # 驻拽爪 专 拽专 专拽 驻注 转
        mock_get_collection.assert_called_once()


def test_full_ai_response():
    """ 拽  砖转砖 砖 -AI  转转 """
    ai_advisor = AIAdvisorRAG()
    
    full_response = "Invest in diversified assets."
    
    with patch("ollamamodel.ollama.generate", return_value={"response": full_response}):
        response = ai_advisor.get_advice("Should I invest in Apple or Google?")
        
        assert response == full_response, "AI response was cut off!"
