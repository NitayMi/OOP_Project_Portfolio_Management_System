import chromadb
from chromadb.utils import embedding_functions
from sentence_transformers import SentenceTransformer

# ×”×’×“×¨×ª ××•×“×œ Embedding (×”××¨×ª ×˜×§×¡×˜ ×œ××¡×¤×¨×™×)
embedding_model = SentenceTransformer("all-MiniLM-L6-v2")  # ××•×“×œ ××”×™×¨, ××ª××™× ×œ××—×©×‘ ×©×œ×š

# ×™×¦×™×¨×ª ×××’×¨ Chroma
client = chromadb.Client()
collection = client.get_or_create_collection("investment_knowledge")

# ×¤×•× ×§×¦×™×” ×œ×™×¦×™×¨×ª embedding
def embed_text(text):
    return embedding_model.encode([text])[0].tolist()

# ×¤×•× ×§×¦×™×” ×œ×˜×¢×™× ×ª ××™×“×¢ ×œ×§×•×œ×§×¦×™×” (vector DB)
def load_data(text_list):
    for idx, text in enumerate(text_list):
        collection.add(
            documents=[text],
            ids=[str(idx)],
            embeddings=[embed_text(text)]
        )
    print("âœ… Knowledge base loaded successfully.")

# ×¤×•× ×§×¦×™×” ×œ×—×™×¤×•×© ×ª×©×•×‘×”
def query(question, top_k=1):
    question_embedding = embed_text(question)
    results = collection.query(query_embeddings=[question_embedding], n_results=top_k)
    if results['documents']:
        return results['documents'][0][0]  # ××—×–×™×¨ ××ª ×”×ª×•×¦××” ×”×›×™ ×“×•××”
    return "âŒ No relevant information found."

# ×“×•×’××” ×œ×©×™××•×© (×¨×§ ×× ××¨×™×¦×™× ××ª ×”×§×•×‘×¥ ×™×©×™×¨×•×ª)
if __name__ == "__main__":
    # ×˜×¢×™× ×ª ×™×“×¢ ×¨××©×•× ×™
    knowledge = [
        "×× ×™×” ×”×™× × ×™×™×¨ ×¢×¨×š ×©××™×™×¦×’ ×‘×¢×œ×•×ª ×—×œ×§×™×ª ×‘×—×‘×¨×”.",
        "××’\"×— ×”×•× × ×™×™×¨ ×¢×¨×š ×”××”×•×•×” ×”×ª×—×™×™×‘×•×ª ×—×•×‘ ××¦×“ ×”×× ×¤×™×§ ×›×œ×¤×™ ×”××—×–×™×§.",
        "×¨××ª ×¡×™×›×•×Ÿ ×’×‘×•×”×” ××ª××™××” ×œ××©×§×™×¢×™× ×©××•×›× ×™× ×œ×§×—×ª ×¡×™×›×•× ×™× ××©××¢×•×ª×™×™× ×ª××•×¨×ª ×ª×©×•××•×ª ×’×‘×•×”×•×ª.",
        "×¤×™×–×•×¨ ×”×©×§×¢×•×ª ×¢×•×–×¨ ×œ×”×§×˜×™×Ÿ ××ª ×”×¡×™×›×•×Ÿ ×”×›×•×œ×œ ×©×œ ×”×ª×™×§."
    ]
    load_data(knowledge)
    
    # ×‘×“×™×§×” ×¢× ×©××œ×”
    question = "××” ×–×” ×× ×™×”?"
    answer = query(question)
    print(f"\nâ“ Question: {question}\nğŸ’¡ Answer: {answer}")
